{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/innovation/ouyangmalin/GW data analysis /baseline/BBH/test 1\n"
     ]
    }
   ],
   "source": [
    "# 先知晓一下当前的目录地址\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.6.1'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://git.ligo.org/lscsoft/lalsuite/-/issues/300\n",
    "import lal\n",
    "lal.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu124'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from main import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams, rc\n",
    "from matplotlib import gridspec\n",
    "params = {'backend': 'pdf',\n",
    "          'axes.labelsize': 12, #坐标轴标签字体\n",
    "          'font.size': 14,\n",
    "          'axes.linewidth':1,\n",
    "          'legend.fontsize': 13, #图例字体大小\n",
    "          'xtick.labelsize': 12,\n",
    "          'ytick.labelsize': 12, #刻度标签字体\n",
    "          'ytick.major.pad': 4,\n",
    "          'xtick.major.pad': 4,\n",
    "          'xtick.major.width': 1,\n",
    "          'ytick.major.width': 1,\n",
    "          'xtick.minor.width': 1,\n",
    "          'ytick.minor.width': 1,\n",
    "          'xtick.major.size': 8,\n",
    "          'ytick.major.size': 8,\n",
    "          'xtick.minor.size': 5,\n",
    "          'ytick.minor.size': 5,\n",
    "          'text.usetex': False,\n",
    "          'font.family':'serif', #字体\n",
    "          # free font similar to Helvetica\n",
    "\t\t  # 'font.sans-serif':'Helvetica',\n",
    "\t\t  # 'text.latex.preamble':[r'\\usepackage{amsmath}',r'\\usepackage{amssymb}']\n",
    "\t\t  }\n",
    "rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters setting\n",
    "fs = 8192 \n",
    "T_obs = 1\n",
    "snr=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 28 19:38:53 2024: using astrophysical logarithmic mass distribution\n",
      "Sat Dec 28 19:38:53 2024: selected bbh masses = 30.32045914816183,9.19103575560883 (chirp mass = 14.051265673903949)\n",
      "Sat Dec 28 19:38:53 2024: selected bbh cos(inclination) = -0.9800794563248911\n",
      "Sat Dec 28 19:38:53 2024: selected bbh polarisation = 0.8122358978935057\n",
      "Sat Dec 28 19:38:53 2024: selected bbh reference phase = 1.7117878897975851\n",
      "Sat Dec 28 19:38:53 2024: selected bbh sky position = 2.993397377686586,0.6998229436827307\n",
      "Sat Dec 28 19:38:53 2024: selected bbh peak amplitude time = 0.69140625\n",
      "Sat Dec 28 19:38:53 2024: signal enters segment at 37.55726527447442 Hz\n",
      "Sat Dec 28 19:38:53 2024: computed starting frequency = 37.55726527447442 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 28 19:38:53 2024: computed H1 Earth centre time delay = 0.0012832599832278344\n",
      "Sat Dec 28 19:38:53 2024: computed the network SNR = 20\n"
     ]
    }
   ],
   "source": [
    "#generate PSD\n",
    "dets=['H1']\n",
    "psds = [gen_psd(fs,T_obs,op='AdvDesign',det=d) for d in dets]\n",
    "\n",
    "#generate noise\n",
    "psd =gen_psd(fs,T_obs)\n",
    "ts_noise=np.array([gen_noise(fs,T_obs,psd.data.data) for psd in psds]).reshape(1,-1)\n",
    "ts_noise_whiten=np.array([whiten_data(t,T_obs,fs,psd.data.data) for t,psd in zip(ts_noise,psds)]).reshape(1,-1)#white\n",
    "\n",
    "#generate singal\n",
    "par_new= gen_par(fs,T_obs)\n",
    "ts_new,_,_ = gen_bbh(fs,T_obs,psds,par=par_new,snr=snr)\n",
    "ts_new_whiten=np.array([whiten_data(t,T_obs,fs,psd.data.data) for t,psd in zip(ts_new,psds)]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Time[sec]')\n",
    "plt.ylabel('Normalised strain')\n",
    "time_axis=np.linspace(0,T_obs, len(ts_noise_whiten[0])) \n",
    "plt.plot(time_axis, ts_noise_whiten[0],label='Noise',linewidth=0.01)  \n",
    "plt.plot(time_axis, ts_new_whiten[0],color='darkorange',label = rf'Signal({int(par_new.m1)}$M_\\odot$ + {int(par_new.m2)}$M_\\odot$), SNR = {snr}',linewidth=0.5)  \n",
    "plt.xlim(0,T_obs)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.savefig('signal'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts, par,masses=sim_data(fs,T_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot signal for training\n",
    "# strian=np.expand_dims(ts[0], 1) \n",
    "# h=strian[0][0][0]\n",
    "# plt.figure()\n",
    "# plt.xlabel('Time[sec]')\n",
    "# plt.ylabel('Normalised strain')\n",
    "# plt.plot(time_axis,h,linewidth=0.01)  \n",
    "# plt.xlim(0,T_obs)\n",
    "# plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "# plt.title(\"Simtulation Data\")\n",
    "# plt.savefig('simdata'+'.pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cuda:1\n",
      "True\n",
      "NVIDIA GeForce RTX 4090\n",
      "GPU available? True\n",
      "GPU available? True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device:{device}')\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "# 优化器参数\n",
    "lr = 0.001 \n",
    "total_epochs = 100 \n",
    "\n",
    "output_freq = 1  \n",
    "Nnoise=25\n",
    "batchsize=8\n",
    "train_nsample_perepoch =10000\n",
    "test_nsample_perepoch =1000\n",
    "\n",
    "dataset_train = DatasetGenerator(fs=fs,T=T_obs,snr=snr,Nnoise=Nnoise,mdist='gh',nsample_perepoch=train_nsample_perepoch)  \n",
    "dataset_test = DatasetGenerator(fs=fs,T=T_obs,snr=snr,Nnoise=Nnoise,mdist='gh',nsample_perepoch=test_nsample_perepoch)  \n",
    "\n",
    "# 创建一个DataLoader\n",
    "data_loader = DataLoader(dataset_train, batch_size=batchsize, shuffle=True,) \n",
    "test_iter = DataLoader(dataset_test, batch_size=batchsize, shuffle=True,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0013, train acc 0.997, test acc 0.987\n",
      "247.2 examples/sec on cuda:1\n",
      "total epochs=100\n"
     ]
    }
   ],
   "source": [
    "#choose model for training\n",
    "model_type='ResNet152' #CNN,ResNet50,ResNet101,ResNet152,LSTM\n",
    "\n",
    "# 模型和损失历史的输出路径\n",
    "checkpoint_dir = f'./checkpoints_{model_type}/'\n",
    "\n",
    "\n",
    "net, epoch, train_loss_history = load_model(checkpoint_dir,model_type=model_type)  \n",
    "net.to(device); \n",
    "\n",
    "total_epochs += epoch \n",
    "# 训练模型\n",
    "train_list_l=[]\n",
    "train_list_acc=[]\n",
    "test_list_acc=[] \n",
    "test_list_l=[] \n",
    "train_list_acc,train_list_l,test_list_acc,test_list_l,train_masses=train(net, lr, train_nsample_perepoch, epoch, total_epochs,\n",
    "      dataset_train, data_loader,test_iter,\n",
    "      train_loss_history, checkpoint_dir,device, notebook=True)\n",
    "print(f'total epochs={total_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_list_acc,color='darkorange',label='training data',linewidth=1.5)\n",
    "plt.plot(test_list_acc,color='royalblue',label='testing data',linewidth=1.5)\n",
    "plt.title(f'Total Epoch={total_epochs}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.savefig(f'acc of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_list_l,color='darkorange',label='training data',linewidth=1.5)\n",
    "plt.plot(test_list_l,color='royalblue',label='testing data',linewidth=1.5)\n",
    "plt.title(f'Total Epoch={total_epochs}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.savefig(f'loss of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def evaluate_gpu(net, data_iter, device=None):\n",
    "    \n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval() \n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device  \n",
    "    softmax = nn.Softmax(dim=-1) \n",
    "    y_hat_list = []  \n",
    "    y_list = []  \n",
    "    with torch.no_grad():  \n",
    "        for X, y in data_iter: \n",
    "            X = X.to(device).to(torch.float) \n",
    "            y = y.to(device).to(torch.long)  \n",
    "            y_hat = net(X)  \n",
    "\n",
    "            preds = softmax(y_hat).cpu().numpy()[:,1].tolist() \n",
    "            labels = y.cpu().numpy().tolist()\n",
    "\n",
    "            y_hat_list.extend(preds)  \n",
    "            y_list.extend(labels)  \n",
    "    return np.asarray(y_hat_list), np.asarray(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/innovation/ouyangmalin/GW data analysis /baseline/BBH/test 1/main.py:293: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(p / files[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load network from checkpoints_ResNet152/model_e73.pt\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "net, epoch, train_loss_history = load_model(checkpoint_dir,model_type=model_type)\n",
    "net.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4159714/1325050731.py:9: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure()\n",
      "100%|██████████| 4/4 [00:36<00:00,  9.16s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "colors = cycle([\"deeppink\", \"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "\n",
    "def sigma(n, tp):\n",
    "    return np.sqrt(tp*(1.-tp)/n)\n",
    "    \n",
    "snr_list = [5, 10, 15, 20]\n",
    "test_masses=[]\n",
    "plt.figure()\n",
    "for snr in tqdm(snr_list):\n",
    "    dataset_test = DatasetGenerator(snr=snr, nsample_perepoch=test_nsample_perepoch, verbose=False)\n",
    "    data_iter = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "    y_hat_list, y_list = evaluate_gpu(net, data_iter, device)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_list, y_hat_list,drop_intermediate=\n",
    "                                     False)\n",
    "    fpr_error = [sigma(len(y_list)/2., t) for t in fpr]\n",
    "    tpr_error = [sigma(len(y_list)/2., t) for t in tpr]\n",
    "\n",
    "    test_masses.append(dataset_test.masses)\n",
    "    \n",
    "    auc = roc_auc_score(y_list, y_hat_list)  \n",
    "    color = next(colors)\n",
    "    plt.plot(fpr, tpr, color=color, label=f'SNR={snr} (AUC={auc:.2f})')\n",
    "    plt.fill_between(fpr, tpr+tpr_error, tpr-tpr_error, alpha=0.2, facecolor=color, zorder=0)\n",
    "plt.plot(*(np.linspace(0,1,100),)*2, 'k--', label='Luck (AUC=0.50)')\n",
    "# plt.axis(\"square\")\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC curves\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(f'ROC1 of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.05s/it]\n"
     ]
    }
   ],
   "source": [
    "snr_list = [2, 4, 6]\n",
    "plt.figure()\n",
    "for snr in tqdm(snr_list):\n",
    "    dataset_test = DatasetGenerator(snr=snr, nsample_perepoch=test_nsample_perepoch, verbose=False)\n",
    "    data_iter = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "    y_hat_list, y_list = evaluate_gpu(net, data_iter, device)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_list, y_hat_list,drop_intermediate=False)\n",
    "    auc = roc_auc_score(y_list, y_hat_list)\n",
    "    \n",
    "    test_masses.append(dataset_test.masses)\n",
    "    \n",
    "    fpr_error = [sigma(len(y_list)/2., t) for t in fpr]\n",
    "    tpr_error = [sigma(len(y_list)/2., t) for t in tpr]\n",
    "    \n",
    "    color = next(colors)\n",
    "    plt.plot(fpr, tpr, color=color, label=f'SNR={snr} (AUC={auc:.2f})')\n",
    "    plt.fill_between(fpr, tpr+tpr_error, tpr-tpr_error, alpha=0.2, facecolor=color, zorder=0)\n",
    "plt.plot(*(np.linspace(0,1,100),)*2, 'k--', label='Luck (AUC=0.50)')\n",
    "# plt.axis(\"square\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC curves\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.xlim(1e-4,1)\n",
    "plt.ylim(1e-4,1)\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(f'ROC2 of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:06<02:12,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:14<02:15,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:21<02:04,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:29<02:00,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:37<01:52,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:43<01:40,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:50<01:32,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:57<01:24,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:04<01:16,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:11<01:11,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:19<01:04,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:26<00:57,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:33<00:50,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:40<00:42,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:48<00:36,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:55<00:29,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [02:02<00:21,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:08<00:13,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:17<00:07,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:24<00:00,  7.21s/it]\n"
     ]
    }
   ],
   "source": [
    "snr_list = np.arange(1, 21, 1)  \n",
    "fap_levels = [0.2, 0.1, 0.05]  \n",
    "\n",
    "tap_bbh = {fap: [] for fap in fap_levels}\n",
    "\n",
    "plt.figure()\n",
    "for snr in tqdm(snr_list):\n",
    "    dataset_test = DatasetGenerator(fs=fs, T=T_obs, snr=snr, mdist='gh', Nnoise=Nnoise, nsample_perepoch=test_nsample_perepoch)\n",
    "    data_iter = DataLoader(dataset_test, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    y_hat_list, y_list = evaluate_gpu(net, data_iter, device)\n",
    "    fpr, tpr, _ = roc_curve(y_list, y_hat_list,drop_intermediate=False)\n",
    "\n",
    "    for fap in fap_levels:\n",
    "        idx = np.argmin(np.abs(fpr - fap)) \n",
    "        tap_bbh[fap].append(tpr[idx])  \n",
    "\n",
    "for fap in fap_levels:\n",
    "    color = next(colors)\n",
    "    plt.plot(snr_list, tap_bbh[fap], label=f\"BBH FAP={fap}\", linestyle=\"-\", color=color,marker='o')\n",
    "\n",
    "plt.xlabel(\"Optimal Matched-Filter SNR\", fontsize=12)\n",
    "plt.ylabel(\"True Alarm Probability\", fontsize=12)\n",
    "plt.title(\"Sensitivity Curves for GW Detection\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.xlim(1,20)\n",
    "plt.ylim(1e-4,1)\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(f'Sensitivity Curves of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Data Size=20000\n",
      "Testing Data Size=160\n"
     ]
    }
   ],
   "source": [
    "#plot mass distribution\n",
    "combined_list1=[]\n",
    "combined_list2=[]\n",
    "for i in range(len(test_masses)):\n",
    "    combined_list1.extend(test_masses[i])\n",
    "for i in range(len(train_masses)):\n",
    "    combined_list2.extend(train_masses[i])\n",
    "train_m1,train_m2=zip(*(combined_list2))\n",
    "test_m1, test_m2=zip(*(combined_list1+dataset_test.masses))\n",
    "plt.figure()\n",
    "plt.scatter(train_m1, train_m2, s=5, alpha=0.8,color='darkorange',label=\"Training Mass distribution\")\n",
    "plt.scatter(test_m1, test_m2, s=5, alpha=0.8,color='royalblue',label=\"Test Mass distribution\")\n",
    "plt.plot([0, max(train_m1)], [0, max(train_m1)], 'k--', label=r\"$M_1 =M_2$\")  \n",
    "plt.xlabel(r\"$M_1$ [$M_\\odot$]\")\n",
    "plt.ylabel(r\"$M_2$ [$M_\\odot$]\")\n",
    "plt.ylim(5,100)\n",
    "plt.xlim(5,100)\n",
    "plt.legend()\n",
    "plt.title(\"Mass Distribution of BBH\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.savefig(f'masses of {model_type}'+'.pdf')           \n",
    "plt.show()\n",
    "#data size\n",
    "print(f'Traning Data Size={len(train_m1)}')\n",
    "print(f'Testing Data Size={len(test_m1)}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7391548,
     "sourceId": 66658,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pycbc",
   "language": "python",
   "name": "pycbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
