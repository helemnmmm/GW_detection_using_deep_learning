{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/innovation/ouyangmalin/GW data analysis /baseline/BNS/test 1\n"
     ]
    }
   ],
   "source": [
    "# 先知晓一下当前的目录地址\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4180226/1428922197.py:2: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(False)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  import lal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7.6.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://git.ligo.org/lscsoft/lalsuite/-/issues/300\n",
    "import lal\n",
    "lal.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu124'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from main import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams, rc\n",
    "from matplotlib import gridspec\n",
    "params = {'backend': 'pdf',\n",
    "          'axes.labelsize': 12, #坐标轴标签字体\n",
    "          'font.size': 14,\n",
    "          'axes.linewidth':1,\n",
    "          'legend.fontsize': 13, #图例字体大小\n",
    "          'xtick.labelsize': 12,\n",
    "          'ytick.labelsize': 12, #刻度标签字体\n",
    "          'ytick.major.pad': 4,\n",
    "          'xtick.major.pad': 4,\n",
    "          'xtick.major.width': 1,\n",
    "          'ytick.major.width': 1,\n",
    "          'xtick.minor.width': 1,\n",
    "          'ytick.minor.width': 1,\n",
    "          'xtick.major.size': 8,\n",
    "          'ytick.major.size': 8,\n",
    "          'xtick.minor.size': 5,\n",
    "          'ytick.minor.size': 5,\n",
    "          'text.usetex': False,\n",
    "          'font.family':'serif', #字体\n",
    "          # free font similar to Helvetica\n",
    "\t\t  # 'font.sans-serif':'Helvetica',\n",
    "\t\t  # 'text.latex.preamble':[r'\\usepackage{amsmath}',r'\\usepackage{amssymb}']\n",
    "\t\t  }\n",
    "rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters setting\n",
    "# fs = 8192 \n",
    "fs = 4096\n",
    "T_obs = 10\n",
    "snr=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts, par,masses= sim_data(fs, T_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 28 18:14:03 2024: using George & Huerta mass distribution\n",
      "Sat Dec 28 18:14:03 2024: selected bns masses = 2.389608306794044,1.3906909515653103 (chirp mass = 1.5755390537418985)\n",
      "Sat Dec 28 18:14:03 2024: selected bns cos(inclination) = -0.5194429200654381\n",
      "Sat Dec 28 18:14:03 2024: selected bns polarisation = 4.519985301518775\n",
      "Sat Dec 28 18:14:03 2024: selected bns reference phase = 1.7098014708546065\n",
      "Sat Dec 28 18:14:03 2024: selected bns sky position = 2.6539522321186295,-1.041744098200801\n",
      "Sat Dec 28 18:14:03 2024: selected bns peak amplitude time = 7.0810546875\n",
      "Sat Dec 28 18:14:03 2024: signal enters segment at 64.75955733767127 Hz\n",
      "Sat Dec 28 18:14:03 2024: computed starting frequency = 64.75955733767127 Hz\n",
      "Sat Dec 28 18:14:03 2024: selected bns tidal deformability= 7.034223944973143,1372.6920739235047\n",
      "Sat Dec 28 18:14:03 2024: selected bns spin= -0.023406789914207207,0.020467878162074363\n",
      "Sat Dec 28 18:14:03 2024: computed H1 Earth centre time delay = 0.020460017230151003\n",
      "Sat Dec 28 18:14:03 2024: computed the network SNR = 30\n"
     ]
    }
   ],
   "source": [
    "#generate PSD\n",
    "dets=['H1']\n",
    "psds = [gen_psd(fs,T_obs,op='AdvDesign',det=d) for d in dets]\n",
    "\n",
    "#generate noise\n",
    "psd =gen_psd(fs,T_obs)\n",
    "ts_noise=np.array([gen_noise(fs,T_obs,psd.data.data) for psd in psds]).reshape(1,-1)\n",
    "ts_noise_whiten=np.array([whiten_data(t,T_obs,fs,psd.data.data) for t,psd in zip(ts_noise,psds)]).reshape(1,-1)#white\n",
    "\n",
    "#generate singal\n",
    "par_new= gen_par(fs,T_obs,mdist='gh')\n",
    "ts_new,_,_ = gen_bns(fs,T_obs,psds,par=par_new,snr=snr)\n",
    "ts_new_whiten=np.array([whiten_data(t,T_obs,fs,psd.data.data) for t,psd in zip(ts_new,psds)]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Time[sec]')\n",
    "plt.ylabel('Normalised strain')\n",
    "time_axis=np.linspace(0, T_obs, len(ts_noise_whiten[0])) \n",
    "plt.plot(time_axis, ts_noise_whiten[0],label='Noise',linewidth=0.01)  \n",
    "plt.plot(time_axis, ts_new_whiten[0],color='darkorange',label = rf'Signal({par_new.m1:.2f}$M_\\odot$ + {par_new.m2:.2f}$M_\\odot$), SNR = {snr}',linewidth=0.001)  \n",
    "plt.xlim(0,T_obs)\n",
    "# plt.xlim(6,7)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.savefig('signal'+'.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot signal for training\n",
    "# strian=np.expand_dims(ts[0], 1) \n",
    "# h=strian[0][0][0]\n",
    "# plt.figure()\n",
    "# plt.xlabel('Time[sec]')\n",
    "# plt.ylabel('Normalised strain')\n",
    "# plt.plot(time_axis,h,linewidth=0.01)  \n",
    "# plt.xlim(0,T_obs)\n",
    "# plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "# plt.title(\"Simtulation Data\")\n",
    "# plt.savefig('simdata'+'.pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cuda:1\n",
      "True\n",
      "NVIDIA GeForce RTX 4090\n",
      "GPU available? True\n",
      "GPU available? True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device:{device}')\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "# 优化器参数\n",
    "lr = 0.001 \n",
    "total_epochs = 100 \n",
    "\n",
    "# output_freq = 1  \n",
    "Nnoise=25\n",
    "batchsize=16\n",
    "train_nsample_perepoch =100\n",
    "test_nsample_perepoch =100\n",
    "\n",
    "dataset_train = DatasetGenerator(fs=fs,T=T_obs,snr=snr,Nnoise=Nnoise,mdist='gh',nsample_perepoch=train_nsample_perepoch)  \n",
    "dataset_test = DatasetGenerator(fs=fs,T=T_obs,snr=snr,Nnoise=Nnoise,mdist='gh',nsample_perepoch=test_nsample_perepoch)  \n",
    "\n",
    "# 创建一个DataLoader\n",
    "data_loader = DataLoader(dataset_train, batch_size=batchsize, shuffle=True,) \n",
    "test_iter = DataLoader(dataset_test, batch_size=batchsize, shuffle=True,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m test_list_acc\u001b[38;5;241m=\u001b[39m[] \n\u001b[1;32m     16\u001b[0m test_list_l\u001b[38;5;241m=\u001b[39m[] \n\u001b[0;32m---> 17\u001b[0m train_list_acc,train_list_l,test_list_acc,test_list_l,train_masses\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_nsample_perepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrain_loss_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/ouyangmalin/GW data analysis /baseline/BNS/test 1/main.py:396\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, nsample_perepoch, epoch, total_epochs, dataset_train, data_loader, test_iter, train_loss_history, checkpoint_dir, device, notebook)\u001b[0m\n\u001b[1;32m    393\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# 将数据和标签转移到设备上，并转换为适当的数据类型\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    397\u001b[0m label \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# 通过网络进行前向传播，得到预测结果\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#choose model for training\n",
    "model_type='ResNet101' #CNN,ResNet50,ResNet101,ResNet152\n",
    "\n",
    "# 模型和损失历史的输出路径\n",
    "checkpoint_dir = f'./checkpoints_{model_type}/'\n",
    "\n",
    "\n",
    "net, epoch, train_loss_history = load_model(checkpoint_dir,model_type=model_type)  \n",
    "net.to(device); \n",
    "\n",
    "total_epochs += epoch \n",
    "# 训练模型\n",
    "train_list_l=[]\n",
    "train_list_acc=[]\n",
    "test_list_acc=[] \n",
    "test_list_l=[] \n",
    "train_list_acc,train_list_l,test_list_acc,test_list_l,train_masses=train(net, lr, train_nsample_perepoch, epoch, total_epochs,\n",
    "      dataset_train, data_loader,test_iter,\n",
    "      train_loss_history, checkpoint_dir,device, notebook=True)\n",
    "print(f'total epochs={total_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_list_acc,color='darkorange',label='training data',linewidth=1.5)\n",
    "plt.plot(test_list_acc,color='royalblue',label='testing data',linewidth=1.5)\n",
    "plt.title(f'Total Epoch={total_epochs}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.savefig(f'acc of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_list_l,color='darkorange',label='training data',linewidth=1.5)\n",
    "plt.plot(test_list_l,color='royalblue',label='testing data',linewidth=1.5)\n",
    "plt.title(f'Total Epoch={total_epochs}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.savefig(f'loss of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def evaluate_gpu(net, data_iter, device=None):\n",
    "    \n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval() \n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device  \n",
    "    softmax = nn.Softmax(dim=-1) \n",
    "    y_hat_list = []  \n",
    "    y_list = []  \n",
    "    with torch.no_grad():  \n",
    "        for X, y in data_iter: \n",
    "            X = X.to(device).to(torch.float) \n",
    "            y = y.to(device).to(torch.long)  \n",
    "            y_hat = net(X)  \n",
    "\n",
    "            preds = softmax(y_hat).cpu().numpy()[:,1].tolist() \n",
    "            labels = y.cpu().numpy().tolist()\n",
    "\n",
    "            y_hat_list.extend(preds)  \n",
    "            y_list.extend(labels)  \n",
    "    return np.asarray(y_hat_list), np.asarray(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/innovation/ouyangmalin/GW data analysis /baseline/BNS/test 1/main.py:262: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(p / files[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load network from checkpoints_ResNet50/model_e27.pt\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "net, epoch, train_loss_history = load_model(checkpoint_dir,model_type=model_type)\n",
    "net.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:22<01:07, 22.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:44<00:44, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:06<00:22, 22.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:28<00:00, 22.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "colors = cycle([\"deeppink\", \"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "\n",
    "def sigma(n, tp):\n",
    "    return np.sqrt(tp*(1.-tp)/n)\n",
    "    \n",
    "snr_list = [5, 10, 15, 20]\n",
    "test_masses=[]\n",
    "plt.figure()\n",
    "for snr in tqdm(snr_list):\n",
    "    dataset_test = DatasetGenerator(fs=fs,T=T_obs,snr=snr,Nnoise=Nnoise,mdist='gh',nsample_perepoch=test_nsample_perepoch)\n",
    "    data_iter = DataLoader(dataset_test, batch_size=batchsize, shuffle=True)\n",
    "    y_hat_list, y_list = evaluate_gpu(net, data_iter, device)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_list, y_hat_list,drop_intermediate=False)\n",
    "    fpr_error = [sigma(len(y_list)/2., t) for t in fpr]\n",
    "    tpr_error = [sigma(len(y_list)/2., t) for t in tpr]\n",
    "\n",
    "    test_masses.append(dataset_test.masses)\n",
    "    \n",
    "    auc = roc_auc_score(y_list, y_hat_list)  \n",
    "    color = next(colors)\n",
    "    plt.plot(fpr, tpr, color=color, label=f'SNR={snr} (AUC={auc:.2f})')\n",
    "    plt.fill_between(fpr, tpr+tpr_error, tpr-tpr_error, alpha=0.2, facecolor=color, zorder=0)\n",
    "plt.plot(*(np.linspace(0,1,100),)*2, 'k--', label='Luck (AUC=0.50)')\n",
    "# plt.axis(\"square\")\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC curves\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(f'ROC1 of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:22<00:45, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:44<00:22, 22.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:06<00:00, 22.07s/it]\n"
     ]
    }
   ],
   "source": [
    "snr_list = [2, 4, 6]\n",
    "plt.figure()\n",
    "for snr in tqdm(snr_list):\n",
    "    dataset_test = DatasetGenerator(fs=fs,T=T_obs,snr=snr,mdist='gh',Nnoise=Nnoise,nsample_perepoch=test_nsample_perepoch)\n",
    "    data_iter = DataLoader(dataset_test, batch_size=batchsize, shuffle=True)\n",
    "    y_hat_list, y_list = evaluate_gpu(net, data_iter, device)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_list, y_hat_list,drop_intermediate=False)\n",
    "    auc = roc_auc_score(y_list, y_hat_list)\n",
    "    \n",
    "    test_masses.append(dataset_test.masses)\n",
    "    \n",
    "    fpr_error = [sigma(len(y_list)/2., t) for t in fpr]\n",
    "    tpr_error = [sigma(len(y_list)/2., t) for t in tpr]\n",
    "    \n",
    "    color = next(colors)\n",
    "    plt.plot(fpr, tpr, color=color, label=f'SNR={snr} (AUC={auc:.2f})')\n",
    "    plt.fill_between(fpr, tpr+tpr_error, tpr-tpr_error, alpha=0.2, facecolor=color, zorder=0)\n",
    "plt.plot(*(np.linspace(0,1,100),)*2, 'k--', label='Luck (AUC=0.50)')\n",
    "# plt.axis(\"square\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC curves\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.xlim(1e-4,1)\n",
    "plt.ylim(1e-4,1)\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(f'ROC2 of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:22<07:16, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:43<06:28, 21.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:05<06:09, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:27<05:48, 21.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:48<05:26, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [02:10<05:02, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:32<04:42, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:54<04:22, 21.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [03:17<04:04, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:40<03:43, 22.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [04:04<03:26, 22.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [04:27<03:04, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [04:49<02:38, 22.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [05:11<02:15, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [05:34<01:52, 22.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [05:56<01:29, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [06:20<01:08, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [06:42<00:45, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [07:04<00:22, 22.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [07:26<00:00, 22.33s/it]\n"
     ]
    }
   ],
   "source": [
    "snr_list = np.arange(1, 21, 1)  \n",
    "fap_levels = [0.2, 0.15, 0.1]  \n",
    "\n",
    "tap_bns = {fap: [] for fap in fap_levels}\n",
    "\n",
    "plt.figure()\n",
    "for snr in tqdm(snr_list):\n",
    "    dataset_test = DatasetGenerator(fs=fs, T=T_obs, snr=snr, mdist='gh', Nnoise=Nnoise, nsample_perepoch=test_nsample_perepoch)\n",
    "    data_iter = DataLoader(dataset_test, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    y_hat_list, y_list = evaluate_gpu(net, data_iter, device)\n",
    "    fpr, tpr, _ = roc_curve(y_list, y_hat_list,drop_intermediate=False)\n",
    "\n",
    "    for fap in fap_levels:\n",
    "        idx = np.argmin(np.abs(fpr - fap)) \n",
    "        tap_bns[fap].append(tpr[idx])  \n",
    "for fap in fap_levels:\n",
    "    color = next(colors)\n",
    "    plt.plot(snr_list, tap_bns[fap], label=f\"BNS FAP={fap}\", linestyle=\"-\", color=color, marker='o')\n",
    "plt.xlabel(\"Optimal Matched-Filter SNR\", fontsize=12)\n",
    "plt.ylabel(\"True Alarm Probability\", fontsize=12)\n",
    "plt.title(\"Sensitivity Curves for GW Detection\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.xlim(1,20)\n",
    "plt.ylim(1e-4,1)\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(f'Sensitivity Curves of {model_type}'+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Data Size=20000\n",
      "Testing Data Size=160\n"
     ]
    }
   ],
   "source": [
    "#plot mass distribution\n",
    "combined_list1=[]\n",
    "combined_list2=[]\n",
    "for i in range(len(test_masses)):\n",
    "    combined_list1.extend(test_masses[i])\n",
    "for i in range(len(train_masses)):\n",
    "    combined_list2.extend(train_masses[i])\n",
    "train_m1,train_m2=zip(*(combined_list2))\n",
    "test_m1, test_m2=zip(*(combined_list1+dataset_test.masses))\n",
    "plt.figure()\n",
    "plt.scatter(train_m1, train_m2, s=10, alpha=0.8,color='darkorange',label=\"Training Mass distribution\")\n",
    "plt.scatter(test_m1, test_m2, s=10, alpha=0.8,color='royalblue',label=\"Test Mass distribution\")\n",
    "plt.plot([0, max(train_m1)], [0, max(train_m1)], 'k--', label=r\"$M_1 =M_2$\")  \n",
    "plt.xlabel(r\"$M_1$ [$M_\\odot$]\")\n",
    "plt.ylabel(r\"$M_2$ [$M_\\odot$]\")\n",
    "plt.ylim(1,2.6)\n",
    "plt.xlim(1,2.6)\n",
    "plt.legend()\n",
    "plt.title(f\"Mass Distribution of BNS\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.savefig(f'masses of {model_type}'+'.pdf')           \n",
    "plt.show()\n",
    "#data size\n",
    "print(f'Traning Data Size={len(train_m1)}')\n",
    "print(f'Testing Data Size={len(test_m1)}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7391548,
     "sourceId": 66658,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pycbc",
   "language": "python",
   "name": "pycbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
